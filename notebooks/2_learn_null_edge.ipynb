{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac997b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository directory: /Users/gillenlu/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/dwpc_rnn\n",
      "Data directory: /Users/gillenlu/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/dwpc_rnn/data\n",
      "Permutations directory: /Users/gillenlu/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/dwpc_rnn/data/permutations\n",
      "Available permutations: ['000.hetmat', '000.hetmat.bak', '001.hetmat']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pathlib\n",
    "import hetmatpy.matrix\n",
    "\n",
    "# Set up paths\n",
    "repo_dir = pathlib.Path('../').resolve()\n",
    "data_dir = repo_dir / 'data'\n",
    "permutations_dir = data_dir / 'permutations'\n",
    "\n",
    "print(f\"Repository directory: {repo_dir}\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Permutations directory: {permutations_dir}\")\n",
    "\n",
    "# List available permutations\n",
    "available_permutations = sorted([p.name for p in permutations_dir.iterdir() if p.is_dir()])\n",
    "print(f\"Available permutations: {available_permutations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab8bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_permutation_data(permutation_name):\n",
    "    \"\"\"\n",
    "    Load AeG edges, Anatomy nodes, and Gene nodes for a specific permutation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    permutation_name : str\n",
    "        Name of the permutation directory (e.g., '001.hetmat')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing loaded data with keys:\n",
    "           - 'aeg_edges': scipy sparse matrix for AeG edges\n",
    "           - 'anatomy_nodes': pandas DataFrame of anatomy nodes\n",
    "           - 'gene_nodes': pandas DataFrame of gene nodes\n",
    "           - 'permutation_path': pathlib.Path to the permutation directory\n",
    "    \"\"\"\n",
    "    # Set up paths for this permutation\n",
    "    perm_dir = permutations_dir / permutation_name\n",
    "    edges_dir = perm_dir / 'edges'\n",
    "    nodes_dir = perm_dir / 'nodes'\n",
    "    \n",
    "    if not perm_dir.exists():\n",
    "        raise FileNotFoundError(f\"Permutation directory not found: {perm_dir}\")\n",
    "    \n",
    "    print(f\"Loading data from permutation: {permutation_name}\")\n",
    "    print(f\"Permutation path: {perm_dir}\")\n",
    "    \n",
    "    # Load AeG edges (Anatomy-expresses-Gene)\n",
    "    aeg_path = edges_dir / 'AeG.sparse.npz'\n",
    "    if not aeg_path.exists():\n",
    "        raise FileNotFoundError(f\"AeG edges file not found: {aeg_path}\")\n",
    "    \n",
    "    aeg_edges = scipy.sparse.load_npz(aeg_path)\n",
    "    print(f\"Loaded AeG edges: {aeg_edges.shape} matrix with {aeg_edges.nnz} non-zero entries\")\n",
    "    \n",
    "    # Load Anatomy nodes\n",
    "    anatomy_path = nodes_dir / 'Anatomy.tsv'\n",
    "    if not anatomy_path.exists():\n",
    "        raise FileNotFoundError(f\"Anatomy nodes file not found: {anatomy_path}\")\n",
    "    \n",
    "    anatomy_nodes = pd.read_csv(anatomy_path, sep='\\t')\n",
    "    print(f\"Loaded Anatomy nodes: {len(anatomy_nodes)} nodes\")\n",
    "    print(f\"Anatomy columns: {list(anatomy_nodes.columns)}\")\n",
    "    \n",
    "    # Load Gene nodes\n",
    "    gene_path = nodes_dir / 'Gene.tsv'\n",
    "    if not gene_path.exists():\n",
    "        raise FileNotFoundError(f\"Gene nodes file not found: {gene_path}\")\n",
    "    \n",
    "    gene_nodes = pd.read_csv(gene_path, sep='\\t')\n",
    "    print(f\"Loaded Gene nodes: {len(gene_nodes)} nodes\")\n",
    "    print(f\"Gene columns: {list(gene_nodes.columns)}\")\n",
    "    \n",
    "    return {\n",
    "        'aeg_edges': aeg_edges,\n",
    "        'anatomy_nodes': anatomy_nodes,\n",
    "        'gene_nodes': gene_nodes,\n",
    "        'permutation_path': perm_dir\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8abdc326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading example data from: 000.hetmat\n",
      "Loading data from permutation: 000.hetmat\n",
      "Permutation path: /Users/gillenlu/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/dwpc_rnn/data/permutations/000.hetmat\n",
      "Loaded AeG edges: (402, 20945) matrix with 526407 non-zero entries\n",
      "Loaded Anatomy nodes: 402 nodes\n",
      "Anatomy columns: ['position', 'identifier', 'name']\n",
      "Loaded Gene nodes: 20945 nodes\n",
      "Gene columns: ['position', 'identifier', 'name']\n",
      "\n",
      "==================================================\n",
      "DATA SUMMARY\n",
      "==================================================\n",
      "AeG edges matrix shape: (402, 20945)\n",
      "AeG edges density: 0.062519\n",
      "Number of Anatomy nodes: 402\n",
      "Number of Gene nodes: 20945\n",
      "\n",
      "Sample Anatomy nodes:\n",
      "   position      identifier                       name\n",
      "0         0  UBERON:0000002             uterine cervix\n",
      "1         1  UBERON:0000004                       nose\n",
      "2         2  UBERON:0000006        islet of Langerhans\n",
      "3         3  UBERON:0000007            pituitary gland\n",
      "4         4  UBERON:0000010  peripheral nervous system\n",
      "\n",
      "Sample Gene nodes:\n",
      "   position  identifier      name\n",
      "0         0           1      A1BG\n",
      "1         1           2       A2M\n",
      "2         2           9      NAT1\n",
      "3         3          10      NAT2\n",
      "4         4          12  SERPINA3\n"
     ]
    }
   ],
   "source": [
    "# Load data from the first available permutation\n",
    "if available_permutations:\n",
    "    # Use the first permutation as an example\n",
    "    example_permutation = available_permutations[0]\n",
    "    print(f\"Loading example data from: {example_permutation}\")\n",
    "    \n",
    "    # Load the data\n",
    "    perm_data = load_permutation_data(example_permutation)\n",
    "    \n",
    "    # Access the loaded data\n",
    "    aeg_edges = perm_data['aeg_edges']\n",
    "    anatomy_nodes = perm_data['anatomy_nodes']\n",
    "    gene_nodes = perm_data['gene_nodes']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DATA SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"AeG edges matrix shape: {aeg_edges.shape}\")\n",
    "    print(f\"AeG edges density: {aeg_edges.nnz / (aeg_edges.shape[0] * aeg_edges.shape[1]):.6f}\")\n",
    "    print(f\"Number of Anatomy nodes: {len(anatomy_nodes)}\")\n",
    "    print(f\"Number of Gene nodes: {len(gene_nodes)}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(\"\\nSample Anatomy nodes:\")\n",
    "    print(anatomy_nodes.head())\n",
    "    \n",
    "    print(\"\\nSample Gene nodes:\")\n",
    "    print(gene_nodes.head())\n",
    "    \n",
    "else:\n",
    "    print(\"No permutations found in the permutations directory!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67b5b05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all available permutations...\n",
      "\n",
      "Loading permutation: 000.hetmat\n",
      "Loading data from permutation: 000.hetmat\n",
      "Permutation path: /Users/gillenlu/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/dwpc_rnn/data/permutations/000.hetmat\n",
      "Loaded AeG edges: (402, 20945) matrix with 526407 non-zero entries\n",
      "Loaded Anatomy nodes: 402 nodes\n",
      "Anatomy columns: ['position', 'identifier', 'name']\n",
      "Loaded Gene nodes: 20945 nodes\n",
      "Gene columns: ['position', 'identifier', 'name']\n",
      "✓ Successfully loaded 000.hetmat\n",
      "\n",
      "Loading permutation: 000.hetmat.bak\n",
      "Loading data from permutation: 000.hetmat.bak\n",
      "Permutation path: /Users/gillenlu/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/dwpc_rnn/data/permutations/000.hetmat.bak\n",
      "✗ Failed to load 000.hetmat.bak: AeG edges file not found: /Users/gillenlu/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/dwpc_rnn/data/permutations/000.hetmat.bak/edges/AeG.sparse.npz\n",
      "\n",
      "Loading permutation: 001.hetmat\n",
      "Loading data from permutation: 001.hetmat\n",
      "Permutation path: /Users/gillenlu/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/Repositories/dwpc_rnn/data/permutations/001.hetmat\n",
      "Loaded AeG edges: (402, 20945) matrix with 526407 non-zero entries\n",
      "Loaded Anatomy nodes: 402 nodes\n",
      "Anatomy columns: ['position', 'identifier', 'name']\n",
      "Loaded Gene nodes: 20945 nodes\n",
      "Gene columns: ['position', 'identifier', 'name']\n",
      "✓ Successfully loaded 001.hetmat\n",
      "\n",
      "Successfully loaded 2 permutations: ['000.hetmat', '001.hetmat']\n"
     ]
    }
   ],
   "source": [
    "def load_all_permutations():\n",
    "    \"\"\"\n",
    "    Load AeG edges, Anatomy nodes, and Gene nodes from all available permutations.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary with permutation names as keys and loaded data as values\n",
    "    \"\"\"\n",
    "    all_permutations = {}\n",
    "    \n",
    "    for perm_name in available_permutations:\n",
    "        try:\n",
    "            print(f\"\\nLoading permutation: {perm_name}\")\n",
    "            perm_data = load_permutation_data(perm_name)\n",
    "            all_permutations[perm_name] = perm_data\n",
    "            print(f\"✓ Successfully loaded {perm_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to load {perm_name}: {e}\")\n",
    "    \n",
    "    return all_permutations\n",
    "\n",
    "# Uncomment the following lines to load all permutations\n",
    "print(\"Loading all available permutations...\")\n",
    "all_perm_data = load_all_permutations()\n",
    "print(f\"\\nSuccessfully loaded {len(all_perm_data)} permutations: {list(all_perm_data.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11651ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network and Machine Learning imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Neural network libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a584f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_edge_prediction_data(permutation_data, sample_negative_ratio=1.0):\n",
    "    \"\"\"\n",
    "    Prepare training data for edge prediction based on source and target degrees.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    permutation_data : dict\n",
    "        Dictionary containing permutation data with AeG edges, anatomy nodes, and gene nodes\n",
    "    sample_negative_ratio : float\n",
    "        Ratio of negative samples to positive samples (1.0 means equal number)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (features, labels) where features are [source_degree, target_degree] \n",
    "            and labels are binary edge existence indicators\n",
    "    \"\"\"\n",
    "    aeg_edges = permutation_data['aeg_edges']\n",
    "    anatomy_nodes = permutation_data['anatomy_nodes']\n",
    "    gene_nodes = permutation_data['gene_nodes']\n",
    "    \n",
    "    # Calculate degrees\n",
    "    anatomy_degrees = np.array(aeg_edges.sum(axis=1)).flatten()  # Row sums (anatomy -> gene connections)\n",
    "    gene_degrees = np.array(aeg_edges.sum(axis=0)).flatten()     # Column sums (gene <- anatomy connections)\n",
    "    \n",
    "    print(f\"Anatomy degree range: {anatomy_degrees.min()} - {anatomy_degrees.max()}\")\n",
    "    print(f\"Gene degree range: {gene_degrees.min()} - {gene_degrees.max()}\")\n",
    "    \n",
    "    # Get positive examples (existing edges)\n",
    "    positive_rows, positive_cols = aeg_edges.nonzero()\n",
    "    positive_features = np.column_stack([\n",
    "        anatomy_degrees[positive_rows],  # Source degrees (anatomy)\n",
    "        gene_degrees[positive_cols]      # Target degrees (genes)\n",
    "    ])\n",
    "    positive_labels = np.ones(len(positive_rows))\n",
    "    \n",
    "    print(f\"Number of positive examples (existing edges): {len(positive_labels)}\")\n",
    "    \n",
    "    # Generate negative examples (non-existing edges)\n",
    "    n_negative = int(len(positive_labels) * sample_negative_ratio)\n",
    "    \n",
    "    # Sample random anatomy-gene pairs that don't have edges\n",
    "    negative_features = []\n",
    "    negative_labels = []\n",
    "    \n",
    "    attempts = 0\n",
    "    max_attempts = n_negative * 10  # Prevent infinite loop\n",
    "    \n",
    "    while len(negative_features) < n_negative and attempts < max_attempts:\n",
    "        # Sample random anatomy and gene indices\n",
    "        anatomy_idx = np.random.randint(0, len(anatomy_nodes))\n",
    "        gene_idx = np.random.randint(0, len(gene_nodes))\n",
    "        \n",
    "        # Check if this pair doesn't have an edge\n",
    "        if aeg_edges[anatomy_idx, gene_idx] == 0:\n",
    "            negative_features.append([anatomy_degrees[anatomy_idx], gene_degrees[gene_idx]])\n",
    "            negative_labels.append(0)\n",
    "        \n",
    "        attempts += 1\n",
    "    \n",
    "    negative_features = np.array(negative_features)\n",
    "    negative_labels = np.array(negative_labels)\n",
    "    \n",
    "    print(f\"Number of negative examples (non-existing edges): {len(negative_labels)}\")\n",
    "    \n",
    "    # Combine positive and negative examples\n",
    "    all_features = np.vstack([positive_features, negative_features])\n",
    "    all_labels = np.concatenate([positive_labels, negative_labels])\n",
    "    \n",
    "    # Shuffle the data\n",
    "    shuffle_idx = np.random.permutation(len(all_labels))\n",
    "    all_features = all_features[shuffle_idx]\n",
    "    all_labels = all_labels[shuffle_idx]\n",
    "    \n",
    "    return all_features, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bbbb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgePredictionNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Network for predicting edge probability based on source and target degrees.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=2, hidden_dims=[64, 32, 16], dropout_rate=0.2):\n",
    "        super(EdgePredictionNN, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        # Create hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output layer with sigmoid activation for probability\n",
    "        layers.append(nn.Linear(prev_dim, 1))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze()\n",
    "\n",
    "# Function to train the model\n",
    "def train_edge_prediction_model(features, labels, test_size=0.2, epochs=100, batch_size=1024, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Train the edge prediction neural network.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    features : numpy.ndarray\n",
    "        Feature matrix with source and target degrees\n",
    "    labels : numpy.ndarray\n",
    "        Binary labels for edge existence\n",
    "    test_size : float\n",
    "        Proportion of data for testing\n",
    "    epochs : int\n",
    "        Number of training epochs\n",
    "    batch_size : int\n",
    "        Batch size for training\n",
    "    learning_rate : float\n",
    "        Learning rate for optimizer\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (model, train_history, test_metrics)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, labels, test_size=test_size, random_state=42, stratify=labels\n",
    "    )\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "    y_train_tensor = torch.FloatTensor(y_train)\n",
    "    X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "    y_test_tensor = torch.FloatTensor(y_test)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = EdgePredictionNN()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training history\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_aucs = []\n",
    "    \n",
    "    print(f\"Training on {len(X_train)} samples, testing on {len(X_test)} samples\")\n",
    "    print(f\"Feature shapes: {X_train.shape}, Labels shape: {y_train.shape}\")\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "        epoch_train_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_predictions = []\n",
    "        val_true = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in test_loader:\n",
    "                outputs = model(batch_X)\n",
    "                val_loss += criterion(outputs, batch_y).item()\n",
    "                val_predictions.extend(outputs.cpu().numpy())\n",
    "                val_true.extend(batch_y.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        val_auc = roc_auc_score(val_true, val_predictions)\n",
    "        \n",
    "        train_losses.append(epoch_train_loss / len(train_loader))\n",
    "        val_losses.append(val_loss / len(test_loader))\n",
    "        val_aucs.append(val_auc)\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val AUC: {val_auc:.4f}\")\n",
    "        \n",
    "        model.train()\n",
    "    \n",
    "    # Final evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_predictions = model(X_test_tensor).cpu().numpy()\n",
    "    \n",
    "    test_auc = roc_auc_score(y_test, test_predictions)\n",
    "    test_ap = average_precision_score(y_test, test_predictions)\n",
    "    \n",
    "    train_history = {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'val_aucs': val_aucs\n",
    "    }\n",
    "    \n",
    "    test_metrics = {\n",
    "        'auc': test_auc,\n",
    "        'average_precision': test_ap,\n",
    "        'predictions': test_predictions,\n",
    "        'true_labels': y_test,\n",
    "        'scaler': scaler\n",
    "    }\n",
    "    \n",
    "    return model, train_history, test_metrics\n",
    "\n",
    "print(\"Neural network architecture and training function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb65a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(train_history):\n",
    "    \"\"\"Plot training history including loss curves and validation AUC.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0].plot(train_history['train_losses'], label='Training Loss')\n",
    "    axes[0].plot(train_history['val_losses'], label='Validation Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Validation AUC\n",
    "    axes[1].plot(train_history['val_aucs'], label='Validation AUC', color='green')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('AUC')\n",
    "    axes[1].set_title('Validation AUC Over Time')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Final validation metrics\n",
    "    final_auc = train_history['val_aucs'][-1]\n",
    "    axes[2].bar(['Final Val AUC'], [final_auc], color='green', alpha=0.7)\n",
    "    axes[2].set_ylabel('AUC Score')\n",
    "    axes[2].set_title('Final Validation Performance')\n",
    "    axes[2].set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model_performance(test_metrics):\n",
    "    \"\"\"Evaluate and visualize model performance.\"\"\"\n",
    "    predictions = test_metrics['predictions']\n",
    "    true_labels = test_metrics['true_labels']\n",
    "    auc = test_metrics['auc']\n",
    "    ap = test_metrics['average_precision']\n",
    "    \n",
    "    print(f\"Test AUC: {auc:.4f}\")\n",
    "    print(f\"Average Precision: {ap:.4f}\")\n",
    "    \n",
    "    # Create evaluation plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # ROC Curve\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fpr, tpr, _ = roc_curve(true_labels, predictions)\n",
    "    axes[0, 0].plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.3f})')\n",
    "    axes[0, 0].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    axes[0, 0].set_xlabel('False Positive Rate')\n",
    "    axes[0, 0].set_ylabel('True Positive Rate')\n",
    "    axes[0, 0].set_title('ROC Curve')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(true_labels, predictions)\n",
    "    axes[0, 1].plot(recall, precision, label=f'PR Curve (AP = {ap:.3f})')\n",
    "    axes[0, 1].set_xlabel('Recall')\n",
    "    axes[0, 1].set_ylabel('Precision')\n",
    "    axes[0, 1].set_title('Precision-Recall Curve')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Prediction distribution\n",
    "    axes[1, 0].hist(predictions[true_labels == 0], bins=50, alpha=0.7, label='Negative', density=True)\n",
    "    axes[1, 0].hist(predictions[true_labels == 1], bins=50, alpha=0.7, label='Positive', density=True)\n",
    "    axes[1, 0].set_xlabel('Predicted Probability')\n",
    "    axes[1, 0].set_ylabel('Density')\n",
    "    axes[1, 0].set_title('Prediction Distribution')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Confusion matrix at different thresholds\n",
    "    thresholds = [0.3, 0.5, 0.7]\n",
    "    threshold_results = []\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        pred_binary = (predictions >= thresh).astype(int)\n",
    "        from sklearn.metrics import confusion_matrix, classification_report\n",
    "        cm = confusion_matrix(true_labels, pred_binary)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        precision_val = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall_val = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1_val = 2 * (precision_val * recall_val) / (precision_val + recall_val) if (precision_val + recall_val) > 0 else 0\n",
    "        \n",
    "        threshold_results.append({\n",
    "            'threshold': thresh,\n",
    "            'precision': precision_val,\n",
    "            'recall': recall_val,\n",
    "            'f1': f1_val\n",
    "        })\n",
    "    \n",
    "    # Plot threshold performance\n",
    "    thresh_df = pd.DataFrame(threshold_results)\n",
    "    x_pos = range(len(thresholds))\n",
    "    width = 0.25\n",
    "    \n",
    "    axes[1, 1].bar([x - width for x in x_pos], thresh_df['precision'], width, label='Precision', alpha=0.8)\n",
    "    axes[1, 1].bar(x_pos, thresh_df['recall'], width, label='Recall', alpha=0.8)\n",
    "    axes[1, 1].bar([x + width for x in x_pos], thresh_df['f1'], width, label='F1-Score', alpha=0.8)\n",
    "    \n",
    "    axes[1, 1].set_xlabel('Threshold')\n",
    "    axes[1, 1].set_ylabel('Score')\n",
    "    axes[1, 1].set_title('Performance at Different Thresholds')\n",
    "    axes[1, 1].set_xticks(x_pos)\n",
    "    axes[1, 1].set_xticklabels([f'{t:.1f}' for t in thresholds])\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return threshold_results\n",
    "\n",
    "print(\"Evaluation and visualization functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f94ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neural network on a single permutation\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING EDGE PREDICTION NEURAL NETWORK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Use the first permutation for training\n",
    "training_permutation = list(all_perm_data.keys())[0]\n",
    "print(f\"Training on permutation: {training_permutation}\")\n",
    "\n",
    "# Prepare training data\n",
    "print(\"\\nPreparing training data...\")\n",
    "features, labels = prepare_edge_prediction_data(\n",
    "    all_perm_data[training_permutation], \n",
    "    sample_negative_ratio=1.0\n",
    ")\n",
    "\n",
    "print(f\"Feature matrix shape: {features.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"Positive examples: {np.sum(labels == 1)}\")\n",
    "print(f\"Negative examples: {np.sum(labels == 0)}\")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining neural network...\")\n",
    "model, train_history, test_metrics = train_edge_prediction_model(\n",
    "    features, labels, \n",
    "    epochs=100,\n",
    "    batch_size=512,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Final Test AUC: {test_metrics['auc']:.4f}\")\n",
    "print(f\"Final Test Average Precision: {test_metrics['average_precision']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training results\n",
    "print(\"Plotting training history...\")\n",
    "plot_training_history(train_history)\n",
    "\n",
    "print(\"\\nEvaluating model performance...\")\n",
    "threshold_results = evaluate_model_performance(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_across_permutations(all_permutation_data, epochs=50):\n",
    "    \"\"\"\n",
    "    Train models across all permutations and compare performance.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    all_permutation_data : dict\n",
    "        Dictionary containing all permutation data\n",
    "    epochs : int\n",
    "        Number of epochs for training each model\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Results for each permutation\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TRAINING ACROSS ALL PERMUTATIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for perm_name, perm_data in all_permutation_data.items():\n",
    "        print(f\"\\nTraining on permutation: {perm_name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            # Prepare data\n",
    "            features, labels = prepare_edge_prediction_data(perm_data, sample_negative_ratio=1.0)\n",
    "            \n",
    "            # Train model\n",
    "            model, train_history, test_metrics = train_edge_prediction_model(\n",
    "                features, labels,\n",
    "                epochs=epochs,\n",
    "                batch_size=512,\n",
    "                learning_rate=0.001\n",
    "            )\n",
    "            \n",
    "            results[perm_name] = {\n",
    "                'model': model,\n",
    "                'train_history': train_history,\n",
    "                'test_metrics': test_metrics,\n",
    "                'features': features,\n",
    "                'labels': labels\n",
    "            }\n",
    "            \n",
    "            print(f\"✓ {perm_name}: AUC = {test_metrics['auc']:.4f}, AP = {test_metrics['average_precision']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to train on {perm_name}: {e}\")\n",
    "            results[perm_name] = None\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_permutation_comparison(all_results):\n",
    "    \"\"\"Plot comparison of model performance across permutations.\"\"\"\n",
    "    \n",
    "    # Extract metrics\n",
    "    perm_names = []\n",
    "    aucs = []\n",
    "    aps = []\n",
    "    \n",
    "    for perm_name, result in all_results.items():\n",
    "        if result is not None:\n",
    "            perm_names.append(perm_name)\n",
    "            aucs.append(result['test_metrics']['auc'])\n",
    "            aps.append(result['test_metrics']['average_precision'])\n",
    "    \n",
    "    # Create comparison plots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # AUC comparison\n",
    "    axes[0].bar(range(len(perm_names)), aucs, alpha=0.7, color='skyblue')\n",
    "    axes[0].set_xlabel('Permutation')\n",
    "    axes[0].set_ylabel('AUC Score')\n",
    "    axes[0].set_title('AUC Scores Across Permutations')\n",
    "    axes[0].set_xticks(range(len(perm_names)))\n",
    "    axes[0].set_xticklabels(perm_names, rotation=45)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(aucs):\n",
    "        axes[0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Average Precision comparison\n",
    "    axes[1].bar(range(len(perm_names)), aps, alpha=0.7, color='lightcoral')\n",
    "    axes[1].set_xlabel('Permutation')\n",
    "    axes[1].set_ylabel('Average Precision')\n",
    "    axes[1].set_title('Average Precision Scores Across Permutations')\n",
    "    axes[1].set_xticks(range(len(perm_names)))\n",
    "    axes[1].set_xticklabels(perm_names, rotation=45)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(aps):\n",
    "        axes[1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nSummary Statistics:\")\n",
    "    print(f\"Mean AUC: {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
    "    print(f\"Mean AP: {np.mean(aps):.4f} ± {np.std(aps):.4f}\")\n",
    "    print(f\"Min AUC: {np.min(aucs):.4f}, Max AUC: {np.max(aucs):.4f}\")\n",
    "    print(f\"Min AP: {np.min(aps):.4f}, Max AP: {np.max(aps):.4f}\")\n",
    "\n",
    "print(\"Multi-permutation training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f8a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Train across all permutations (uncomment to run)\n",
    "# This will take longer as it trains a separate model for each permutation\n",
    "\n",
    "# all_results = train_across_permutations(all_perm_data, epochs=50)\n",
    "# plot_permutation_comparison(all_results)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NEURAL NETWORK SETUP COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"✓ Data loading functions defined\")\n",
    "print(\"✓ Neural network architecture implemented\")\n",
    "print(\"✓ Training pipeline established\")\n",
    "print(\"✓ Evaluation and visualization tools ready\")\n",
    "print(\"✓ Single permutation model trained\")\n",
    "print(\"\\nTo train across all permutations, uncomment the lines above.\")\n",
    "print(\"The model predicts edge probability based on source and target node degrees.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dwpc_rnn_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
